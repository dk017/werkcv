import { CVExample } from '../../types';

export const dataEngineer: CVExample = {
    slug: 'data-engineer',
    categorySlug: 'technologie-en-ict',
    name: 'Data Engineer',
    description: 'CV voorbeeld voor data engineers. Laat zien hoe je je ervaring met datapipelines, cloud-infrastructuur en ETL-processen overtuigend presenteert.',
    templateId: 'robust',
    colorThemeId: 'modern-teal',

    metaTitle: 'CV Voorbeeld Data Engineer | WerkCV.nl',
    metaDesc: 'Professioneel CV voorbeeld voor data engineers. Met voorbeeldteksten voor datapipelines, cloud en ETL, tips en een gratis template. Maak direct je eigen CV.',
    keywords: ['cv voorbeeld data engineer', 'cv data pipeline', 'cv etl specialist', 'data engineer cv maken', 'big data cv'],
    heroTitle: 'CV Voorbeeld Data Engineer',
    heroText: 'Als data engineer ben je de ruggengraat van datagedreven organisaties. Dit CV voorbeeld laat zien hoe je je technische expertise met cloud-platforms, datapipelines en ETL-processen overtuigend presenteert. Benadruk je impact op datakwaliteit en bedrijfsresultaten.',
    tips: [
        'Benoem specifieke cloud-platforms en tools: AWS, Azure, GCP, Spark, Airflow, dbt',
        'Toon de schaal van je werk: "datapipeline verwerkte dagelijks 50 miljoen records"',
        'Vermeld certificeringen zoals AWS Data Analytics of Google Professional Data Engineer',
        'Beschrijf hoe jouw werk bijdraagt aan betere besluitvorming door de organisatie',
        'Laat zien dat je zowel batch- als real-time dataverwerkingspatronen beheerst',
    ],
    relatedSlugs: ['technologie-en-ict/software-ontwikkelaar', 'technologie-en-ict/cybersecurity-specialist'],

    sampleCV: {
        personal: {
            name: 'Priya Bakker',
            title: 'Data Engineer',
            email: 'priya.bakker@email.nl',
            phone: '06-34567890',
            location: 'Eindhoven',
            address: 'Stratumseind 28',
            postalCode: '5611 ET',
            summary: 'Data engineer met 5 jaar ervaring in het ontwerpen en bouwen van schaalbare datapipelines in cloud-omgevingen. Gespecialiseerd in AWS en Azure met expertise in Python, Spark en dbt. Sterk in het vertalen van bedrijfsbehoeften naar robuuste data-architectuur die betrouwbare analytics en machine learning mogelijk maakt.',
            birthDate: '7 november 1995',
            birthPlace: 'Eindhoven',
            nationality: 'Nederlands',
            driversLicense: 'B',
            gender: '',
            maritalStatus: '',
            linkedIn: 'linkedin.com/in/priyabakker',
            github: 'github.com/priyabakker',
            website: '',
            photo: '',
        },
        experience: [
            {
                role: 'Senior Data Engineer',
                company: 'ASML',
                location: 'Veldhoven',
                start: 'januari 2022',
                end: 'heden',
                description: 'Verantwoordelijk voor het ontwerp en beheer van de data-infrastructuur ter ondersteuning van productie-analyse en kwaliteitscontrole.',
                highlights: [
                    'End-to-end datapipeline gebouwd in Apache Spark en Airflow die dagelijks 80 miljoen sensormetingen verwerkt',
                    'Data lakehouse-architectuur geïmplementeerd op AWS met S3, Glue en Redshift, wat querysnelheid met 70% verbeterde',
                    'dbt-modellen ontwikkeld voor gestandaardiseerde datatransformaties, gebruikt door 5 data science teams',
                ],
            },
            {
                role: 'Data Engineer',
                company: 'Rabobank',
                location: 'Utrecht',
                start: 'augustus 2019',
                end: 'december 2021',
                description: 'Bouwde en onderhield datapipelines voor risico-analyse en compliance-rapportage binnen de afdeling Risk Management.',
                highlights: [
                    'ETL-processen gemigreerd van on-premise naar Azure Data Factory, wat verwerkingstijd met 55% reduceerde',
                    'Real-time streamingpipeline opgezet met Kafka en Azure Event Hubs voor fraudedetectie',
                    'Data governance framework geïmplementeerd met geautomatiseerde datakwaliteitscontroles in Great Expectations',
                ],
            },
        ],
        education: [
            {
                degree: 'Master Data Science & Technology',
                school: 'Technische Universiteit Eindhoven',
                location: 'Eindhoven',
                start: 'september 2017',
                end: 'juli 2019',
                description: 'Focus op large-scale data processing en distributed systems. Scriptie over optimalisatie van Spark-jobs voor IoT-sensordata.',
            },
            {
                degree: 'Bachelor Technische Informatica',
                school: 'Fontys Hogescholen',
                location: 'Eindhoven',
                start: 'september 2013',
                end: 'juli 2017',
                description: 'Specialisatie Data & Analytics. Minorproject bij Philips over predictive maintenance.',
            },
        ],
        skills: [
            { name: 'Python / PySpark', level: 5 },
            { name: 'SQL / dbt', level: 5 },
            { name: 'AWS (S3, Glue, Redshift)', level: 4 },
            { name: 'Apache Airflow / Kafka', level: 4 },
            { name: 'Azure Data Factory', level: 4 },
            { name: 'Docker / Terraform', level: 3 },
        ],
        languages: [
            { name: 'Nederlands', level: 'Moedertaal' },
            { name: 'Engels', level: 'Vloeiend' },
            { name: 'Hindi', level: 'Goed' },
        ],
        interests: ['Data visualisatie', 'Kaggle competities', 'Hardlopen', 'Koken'],
        courses: [
            { name: 'AWS Certified Data Analytics - Specialty', institution: 'Amazon Web Services', year: '2023' },
            { name: 'Databricks Certified Data Engineer Associate', institution: 'Databricks', year: '2022' },
        ],
        internships: [],
        awards: [],
    },
};
